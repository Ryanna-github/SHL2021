{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torchsummary import summary\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "source": [
    "# Setting"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"dark_background\")"
   ]
  },
  {
   "source": [
    "# Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, feature_size, hidden_dim, lstm_layer, dropout = 0.2):\n",
    "        super(BiLSTM, self).__init__()\n",
    "        self.input_size = feature_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout = nn.Dropout(p = dropout)\n",
    "        self.lstm = nn.LSTM(input_size = self.input_size, \n",
    "                            hidden_size = hidden_dim,\n",
    "                            num_layers = lstm_layer,\n",
    "                            dropout = dropout,\n",
    "                            bidirectional = True)\n",
    "        self.hidden2label = nn.Linear(hidden_dim*2, 8)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        return lstm_out\n",
    "        # label_space = self.hidden2label(lstm_out)\n",
    "        # label_scores = F.log_softmax(label_space, dim = 1)\n",
    "        # return label_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = torch.rand([1, 1000, 32])\n",
    "net = BiLSTM(32, 128, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = net(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([5, 2, 3, 7, 7, 8, 2, 6, 1, 8, 8, 2, 6, 4, 7, 6, 6, 7, 8, 3, 5, 3,\n",
       "       1, 7, 3, 2, 8, 6, 7, 1, 7, 7, 3, 8, 7, 2, 8, 5, 4, 4, 4, 1, 1, 1,\n",
       "       5, 3, 6, 4, 8, 6, 7, 1, 1, 2, 5, 4, 6, 3, 2, 3, 7, 6, 7, 5, 8, 7,\n",
       "       5, 4, 6, 3, 2, 6, 5, 1, 7, 7, 8, 2, 4, 3, 5, 5, 2, 4, 3, 3, 1, 8,\n",
       "       6, 3, 3, 8, 2, 8, 1, 5, 8, 4, 2, 2, 5, 5, 3, 6, 5, 2, 7, 1, 3, 2,\n",
       "       3, 4, 6, 4, 4, 2, 3, 2, 4, 1, 7, 1, 2, 7, 8, 3, 2, 1, 7, 8, 7, 5,\n",
       "       4, 4, 8, 1, 5, 8, 7, 1, 1, 5, 7, 3, 8, 3, 1, 2, 5, 8, 1, 3, 7, 7,\n",
       "       2, 4, 8, 8, 6, 6, 3, 7, 3, 2, 3, 3, 8, 1, 6, 1, 3, 4, 3, 4, 4, 3,\n",
       "       3, 7, 2, 2, 1, 8, 7, 6, 3, 3, 1, 8, 2, 4, 4, 6, 2, 2, 2, 3, 2, 8,\n",
       "       8, 5, 1, 4, 5, 6, 1, 7, 4, 2, 4, 4, 8, 3, 6, 2, 3, 8, 2, 8, 8, 4,\n",
       "       2, 8, 8, 6, 1, 1, 1, 7, 7, 3, 7, 3, 8, 7, 4, 2, 5, 6, 2, 4, 5, 8,\n",
       "       4, 3, 8, 5, 4, 2, 8, 7, 2, 3, 7, 8, 7, 4, 8, 8, 3, 3, 7, 6, 7, 5,\n",
       "       6, 4, 2, 1, 7, 5, 2, 3, 4, 1, 7, 1, 6, 4, 4, 7, 8, 3, 1, 6, 8, 1,\n",
       "       2, 4, 2, 2, 5, 8, 6, 7, 5, 6, 2, 2, 8, 5, 3, 6, 1, 4, 5, 1, 7, 4,\n",
       "       4, 4, 2, 7, 5, 2, 3, 4, 3, 2, 2, 8, 5, 6, 1, 6, 3, 8, 7, 2, 2, 2,\n",
       "       3, 5, 3, 5, 2, 8, 3, 3, 5, 8, 5, 1, 3, 6, 6, 7, 5, 6, 8, 6, 3, 3,\n",
       "       8, 8, 3, 5, 2, 7, 6, 6, 3, 2, 4, 2, 2, 1, 4, 1, 4, 5, 7, 3, 2, 2,\n",
       "       3, 6, 7, 4, 6, 6, 3, 6, 5, 6, 5, 8, 8, 8, 6, 5, 2, 3, 2, 5, 5, 5,\n",
       "       2, 2, 7, 3, 1, 6, 5, 4, 4, 2, 6, 1, 7, 7, 2, 5, 7, 1, 2, 7, 2, 4,\n",
       "       7, 4, 4, 4, 6, 2, 3, 1, 2, 5, 1, 5, 7, 6, 7, 1, 3, 2, 3, 4, 5, 1,\n",
       "       6, 4, 2, 3, 6, 3, 2, 8, 6, 6, 1, 6, 4, 1, 4, 4, 6, 3, 7, 3, 2, 2,\n",
       "       7, 2, 8, 6, 4, 5, 3, 3, 4, 1, 8, 7, 1, 8, 5, 6, 4, 3, 1, 4, 2, 8,\n",
       "       4, 5, 2, 3, 2, 2, 1, 7, 5, 7, 4, 2, 3, 4, 7, 4, 2, 5, 6, 5, 1, 1,\n",
       "       6, 4, 4, 2, 3, 4, 5, 2, 7, 8, 1, 4, 6, 4, 4, 5, 4, 4, 5, 6, 4, 5,\n",
       "       5, 1, 7, 2, 7, 2, 2, 3, 8, 6, 2, 3, 6, 5, 1, 3, 7, 8, 1, 2, 2, 7,\n",
       "       5, 5, 6, 3, 8, 6, 6, 2, 4, 7, 2, 4, 3, 2, 7, 3, 6, 6, 3, 1, 6, 5,\n",
       "       5, 7, 4, 4, 5, 7, 7, 3, 3, 6, 8, 2, 8, 3, 7, 5, 8, 2, 3, 4, 2, 1,\n",
       "       1, 3, 7, 2, 3, 6, 2, 1, 4, 3, 1, 6, 2, 8, 3, 8, 8, 2, 6, 6, 3, 4,\n",
       "       1, 4, 2, 3, 8, 7, 3, 7, 7, 8, 1, 2, 4, 7, 4, 5, 7, 5, 7, 5, 7, 8,\n",
       "       5, 3, 2, 6, 5, 7, 6, 4, 6, 7, 3, 6, 2, 1, 6, 6, 1, 7, 7, 5, 7, 1,\n",
       "       3, 2, 3, 6, 8, 3, 2, 7, 5, 2, 4, 2, 1, 1, 6, 7, 6, 7, 8, 2, 7, 5,\n",
       "       5, 3, 2, 4, 2, 6, 3, 2, 5, 3, 7, 5, 7, 5, 6, 2, 2, 7, 7, 5, 4, 1,\n",
       "       3, 4, 4, 8, 1, 3, 2, 7, 5, 3, 8, 7, 3, 7, 5, 3, 7, 1, 2, 2, 6, 5,\n",
       "       2, 2, 5, 7, 4, 7, 7, 2, 2, 2, 1, 6, 3, 4, 8, 6, 6, 4, 4, 1, 2, 1,\n",
       "       5, 5, 1, 7, 1, 7, 6, 3, 4, 4, 6, 3, 4, 2, 3, 6, 3, 3, 7, 2, 6, 3,\n",
       "       6, 1, 4, 6, 7, 5, 8, 5, 3, 8, 1, 3, 7, 8, 7, 5, 4, 2, 8, 8, 3, 5,\n",
       "       3, 5, 1, 7, 4, 6, 6, 1, 1, 3, 1, 8, 2, 3, 5, 3, 5, 1, 3, 3, 4, 7,\n",
       "       4, 3, 3, 8, 2, 2, 1, 4, 6, 6, 3, 1, 7, 5, 2, 5, 8, 1, 7, 4, 5, 7,\n",
       "       1, 7, 4, 5, 3, 3, 5, 7, 4, 4, 1, 2, 8, 4, 5, 3, 5, 2, 8, 2, 3, 1,\n",
       "       1, 1, 3, 5, 4, 6, 5, 6, 4, 1, 6, 1, 5, 1, 4, 2, 6, 3, 3, 6, 2, 6,\n",
       "       4, 3, 8, 2, 3, 8, 8, 2, 3, 8, 2, 2, 5, 2, 5, 4, 1, 1, 4, 7, 3, 1,\n",
       "       5, 3, 1, 8, 6, 8, 6, 3, 1, 3, 3, 8, 5, 4, 7, 5, 3, 1, 2, 3, 1, 8,\n",
       "       2, 6, 2, 6, 7, 2, 3, 3, 3, 3, 2, 4, 4, 1, 7, 3, 6, 2, 4, 1, 5, 6,\n",
       "       5, 6, 1, 4, 5, 3, 4, 8, 2, 8, 4, 5, 6, 3, 1, 3, 4, 4, 1, 5, 5, 3,\n",
       "       7, 8, 3, 3, 7, 3, 8, 7, 7, 4, 3, 2, 4, 6, 8, 2, 4, 6, 3, 3, 8, 2,\n",
       "       7, 1, 7, 8, 4, 7, 3, 3, 3, 5])"
      ]
     },
     "metadata": {},
     "execution_count": 137
    }
   ],
   "source": [
    "pred.squeeze().detach().numpy().argmax(axis = 1) + 1"
   ]
  },
  {
   "source": [
    "# Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('data/mid_res/20210526_data_df.csv')\n",
    "val_df = pd.read_csv('data/mid_res/20210526_val_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_drop_x = ['time', 'label']\n",
    "col_label = 'label'\n",
    "col_drop = ['latitude',\n",
    " 'longitude',\n",
    " 'altitude',\n",
    " 'time_dlt',\n",
    " 'valid_dlt',\n",
    " 'east',\n",
    " 'north',\n",
    " 'east_dlt',\n",
    " 'north_dlt',\n",
    " 'east_speed',\n",
    " 'north_speed',\n",
    " 'cells_ctype_mode',\n",
    " 'speed_dif',\n",
    " 'speed_dlt',\n",
    " 'speed'\n",
    " ]\n",
    "X_train, y_train = data_df.drop(col_drop_x + col_drop, axis = 1).fillna(0), data_df[col_label]\n",
    "X_val, y_val = val_df.drop(col_drop_x + col_drop, axis = 1).fillna(0), val_df[col_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(980527, 32)"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TMR_Dataset(Dataset):\n",
    "    def __init__(self, x_array):\n",
    "        super().__init__()\n",
    "        self.len, self.feature_size = x_array.shape\n",
    "        self.data = x_array\n",
    "        self.data = torch.tensor(self.data)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "\n",
    "data = TMR_Dataset(np.array(X_train))\n",
    "data_loader = DataLoader(data, batch_size = BATCH_SIZE, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next(iter(data_loader)).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(torch.Size([1, 4, 32]), torch.Size([1, 1000, 32]))"
      ]
     },
     "metadata": {},
     "execution_count": 270
    }
   ],
   "source": [
    "x.shape, sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 1000, 256])\ntorch.Size([1, 1000, 8])\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[-6.9061, -6.9084, -6.9085,  ..., -6.9083, -6.9065, -6.9093],\n",
       "         [-6.9072, -6.9078, -6.9077,  ..., -6.9078, -6.9066, -6.9091],\n",
       "         [-6.9077, -6.9086, -6.9086,  ..., -6.9082, -6.9098, -6.9090],\n",
       "         ...,\n",
       "         [-6.9062, -6.9069, -6.9086,  ..., -6.9076, -6.9075, -6.9044],\n",
       "         [-6.9075, -6.9070, -6.9068,  ..., -6.9069, -6.9089, -6.9073],\n",
       "         [-6.9087, -6.9073, -6.9093,  ..., -6.9076, -6.9072, -6.9083]]],\n",
       "       grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 271
    }
   ],
   "source": [
    "net(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[  0.0000,   4.0000,   6.0000,   0.0000,   0.0000, -48.0000, -60.6667,\n",
       "          -90.0000, -43.0000,  17.9518,   0.1667,   0.0000,   0.0000,   0.0000,\n",
       "            0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "            0.0000,   0.0000,  22.5000,  16.0000,  29.0000,   5.6862,   0.0000,\n",
       "            0.0000,   0.0000,   3.2450,   0.0000],\n",
       "         [  0.0000,   4.0000,   6.0000,   0.0000,   0.0000, -48.0000, -60.6667,\n",
       "          -90.0000, -43.0000,  17.9518,   0.1667,   0.0000,   0.0000,   0.0000,\n",
       "            0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "            0.0000,   0.0000,  22.2500,  15.0000,  29.0000,   6.0759,   0.0000,\n",
       "            0.0000,   0.0000,   3.2450,   0.0000],\n",
       "         [  0.0000,   4.0000,   6.0000,   0.0000,   0.0000, -48.0000, -60.6667,\n",
       "          -90.0000, -43.0000,  17.9518,   0.1667,   0.0000,   0.0000,   0.0000,\n",
       "            0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "            0.0000,   0.0000,  22.2500,  15.0000,  29.0000,   6.0759,   0.0000,\n",
       "            0.0000,   0.0000,   3.2450,   0.0000],\n",
       "         [  0.0000,   4.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "            0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "            0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,   0.0000,\n",
       "            0.0000,   0.0000,  22.0000,  15.0000,  28.0000,   5.7155,   0.0000,\n",
       "            0.0000,   0.0000,   3.2450,   0.0000]]], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "execution_count": 272
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}