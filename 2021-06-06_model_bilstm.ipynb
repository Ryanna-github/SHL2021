{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torchsummary import summary\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import precision_score, confusion_matrix, f1_score, accuracy_score, recall_score, classification_report\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "source": [
    "# Setting"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"dark_background\")"
   ]
  },
  {
   "source": [
    "# Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, feature_size, hidden_size, lstm_layer, dropout = 0.2):\n",
    "        super(BiLSTM, self).__init__()\n",
    "        self.input_size = feature_size\n",
    "        self.hidden_dim = hidden_size\n",
    "        self.dropout = nn.Dropout(p = dropout)\n",
    "        self.lstm = nn.LSTM(input_size = self.input_size, \n",
    "                            hidden_size = hidden_size,\n",
    "                            num_layers = lstm_layer,\n",
    "                            dropout = dropout,\n",
    "                            bidirectional = True)\n",
    "        self.hidden2label = nn.Linear(hidden_size*2, 8)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        label_space = self.hidden2label(lstm_out)\n",
    "        label_scores = nn.Softmax(dim = 1)(label_space)\n",
    "\n",
    "        return label_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = torch.rand([1, 1000, 32])\n",
    "net = BiLSTM(feature_size = 32, hidden_size = 128, lstm_layer = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 1000, 8])"
      ]
     },
     "metadata": {},
     "execution_count": 358
    }
   ],
   "source": [
    "pred = net(sample)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = list(pred.flatten().detach().numpy())\n",
    "# plt.hist(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1, 5, 5, 1, 5, 8, 1, 2, 2, 7, 7, 5, 5, 5, 5, 7, 2, 8, 2, 4, 1, 1,\n",
       "       3, 4, 8, 3, 8, 6, 2, 3, 7, 3, 8, 7, 4, 2, 1, 6, 1, 1, 5, 4, 6, 4,\n",
       "       5, 6, 6, 6, 4, 7, 4, 4, 6, 7, 4, 2, 5, 2, 2, 3, 6, 4, 7, 7, 3, 7,\n",
       "       3, 1, 7, 5, 2, 4, 8, 5, 4, 5, 8, 1, 2, 2, 5, 2, 8, 8, 7, 2, 6, 7,\n",
       "       1, 1, 8, 6, 1, 4, 5, 7, 1, 8, 5, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 361
    }
   ],
   "source": [
    "# predicted label example\n",
    "(pred.squeeze().detach().numpy().argmax(axis = 1) + 1)[:100]"
   ]
  },
  {
   "source": [
    "# Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('data/mid_res/20210526_data_df.csv')\n",
    "val_df = pd.read_csv('data/mid_res/20210526_val_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_drop_x = ['time', 'label']\n",
    "col_label = 'label'\n",
    "col_drop = ['latitude',\n",
    " 'longitude',\n",
    " 'altitude',\n",
    " 'time_dlt',\n",
    " 'valid_dlt',\n",
    " 'east',\n",
    " 'north',\n",
    " 'east_dlt',\n",
    " 'north_dlt',\n",
    " 'east_speed',\n",
    " 'north_speed',\n",
    " 'cells_ctype_mode',\n",
    " 'speed_dif',\n",
    " 'speed_dlt',\n",
    " 'speed'\n",
    " ]\n",
    "X_train, y_train = data_df.drop(col_drop_x + col_drop, axis = 1).fillna(0), data_df[col_label]\n",
    "X_val, y_val = val_df.drop(col_drop_x + col_drop, axis = 1).fillna(0), val_df[col_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(980527, 32)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TMR_Dataset(Dataset):\n",
    "    def __init__(self, x_array, label):\n",
    "        super().__init__()\n",
    "        self.len, self.feature_size = x_array.shape\n",
    "        self.data = x_array\n",
    "        self.data = torch.tensor(self.data).float()\n",
    "        self.label = label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.data[idx,:], self.label[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "EPOCHS = 10\n",
    "LR = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = TMR_Dataset(np.array(X_train), y_train - 1)\n",
    "train_loader = DataLoader(data, batch_size = BATCH_SIZE, shuffle = False)\n",
    "X_val = torch.tensor(np.array(X_val), dtype = torch.float32)\n",
    "y_val = y_val - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = BiLSTM(feature_size = 32, hidden_size = 4, lstm_layer = 4)\n",
    "# X, y = next(iter(train_loader))\n",
    "# net(X.unsqueeze(0)).squeeze().argmax(dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(log_dir = 'log', comment = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = BiLSTM(feature_size = 32, hidden_size = 64, lstm_layer = 4).to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr = LR)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cy:0.05\n",
      "epoch:0  | iteration:3300 | loss:2.0794 | accuracy:0.05\n",
      "epoch:0  | iteration:3400 | loss:2.0794 | accuracy:0.05\n",
      "epoch:0  | iteration:3500 | loss:2.0794 | accuracy:0.09\n",
      "epoch:0  | iteration:3600 | loss:2.0794 | accuracy:0.16\n",
      "epoch:0  | iteration:3700 | loss:2.0794 | accuracy:0.05\n",
      "epoch:0  | iteration:3800 | loss:2.0794 | accuracy:0.06\n",
      "epoch:1  | iteration:0    | loss:2.0794 | accuracy:0.06\n",
      "epoch:1  | iteration:100  | loss:2.0794 | accuracy:0.00\n",
      "epoch:1  | iteration:200  | loss:2.0794 | accuracy:0.01\n",
      "epoch:1  | iteration:300  | loss:2.0794 | accuracy:0.00\n",
      "epoch:1  | iteration:400  | loss:2.0794 | accuracy:0.07\n",
      "epoch:1  | iteration:500  | loss:2.0794 | accuracy:0.04\n",
      "epoch:1  | iteration:600  | loss:2.0794 | accuracy:0.04\n",
      "epoch:1  | iteration:700  | loss:2.0794 | accuracy:0.04\n",
      "epoch:1  | iteration:800  | loss:2.0794 | accuracy:0.04\n",
      "epoch:1  | iteration:900  | loss:2.0794 | accuracy:0.07\n",
      "epoch:1  | iteration:1000 | loss:2.0794 | accuracy:0.13\n",
      "epoch:1  | iteration:1100 | loss:2.0794 | accuracy:0.04\n",
      "epoch:1  | iteration:1200 | loss:2.0794 | accuracy:0.07\n",
      "epoch:1  | iteration:1300 | loss:2.0794 | accuracy:0.07\n",
      "epoch:1  | iteration:1400 | loss:2.0794 | accuracy:0.04\n",
      "epoch:1  | iteration:1500 | loss:2.0794 | accuracy:0.04\n",
      "epoch:1  | iteration:1600 | loss:2.0794 | accuracy:0.07\n",
      "epoch:1  | iteration:1700 | loss:2.0794 | accuracy:0.08\n",
      "epoch:1  | iteration:1800 | loss:2.0794 | accuracy:0.04\n",
      "epoch:1  | iteration:1900 | loss:2.0794 | accuracy:0.03\n",
      "epoch:1  | iteration:2000 | loss:2.0795 | accuracy:0.04\n",
      "epoch:1  | iteration:2100 | loss:2.0794 | accuracy:0.03\n",
      "epoch:1  | iteration:2200 | loss:2.0794 | accuracy:0.08\n",
      "epoch:1  | iteration:2300 | loss:2.0794 | accuracy:0.05\n",
      "epoch:1  | iteration:2400 | loss:2.0794 | accuracy:0.04\n",
      "epoch:1  | iteration:2500 | loss:2.0794 | accuracy:0.04\n",
      "epoch:1  | iteration:2600 | loss:2.0794 | accuracy:0.04\n",
      "epoch:1  | iteration:2700 | loss:2.0794 | accuracy:0.04\n",
      "epoch:1  | iteration:2800 | loss:2.0762 | accuracy:0.00\n",
      "epoch:1  | iteration:2900 | loss:2.0794 | accuracy:0.08\n",
      "epoch:1  | iteration:3000 | loss:2.0794 | accuracy:0.07\n",
      "epoch:1  | iteration:3100 | loss:2.0794 | accuracy:0.01\n",
      "epoch:1  | iteration:3200 | loss:2.0794 | accuracy:0.00\n",
      "epoch:1  | iteration:3300 | loss:2.0794 | accuracy:0.00\n",
      "epoch:1  | iteration:3400 | loss:2.0794 | accuracy:0.00\n",
      "epoch:1  | iteration:3500 | loss:2.0794 | accuracy:0.00\n",
      "epoch:1  | iteration:3600 | loss:2.0795 | accuracy:0.03\n",
      "epoch:1  | iteration:3700 | loss:2.0794 | accuracy:0.04\n",
      "epoch:1  | iteration:3800 | loss:2.0794 | accuracy:0.04\n",
      "epoch:2  | iteration:0    | loss:2.0794 | accuracy:0.04\n",
      "epoch:2  | iteration:100  | loss:2.0794 | accuracy:0.04\n",
      "epoch:2  | iteration:200  | loss:2.0794 | accuracy:0.08\n",
      "epoch:2  | iteration:300  | loss:2.0794 | accuracy:0.07\n",
      "epoch:2  | iteration:400  | loss:2.0794 | accuracy:0.04\n",
      "epoch:2  | iteration:500  | loss:2.0794 | accuracy:0.07\n",
      "epoch:2  | iteration:600  | loss:2.0794 | accuracy:0.03\n",
      "epoch:2  | iteration:700  | loss:2.0794 | accuracy:0.03\n",
      "epoch:2  | iteration:800  | loss:2.0794 | accuracy:0.04\n",
      "epoch:2  | iteration:900  | loss:2.0794 | accuracy:0.04\n",
      "epoch:2  | iteration:1000 | loss:2.0794 | accuracy:0.04\n",
      "epoch:2  | iteration:1100 | loss:2.0794 | accuracy:0.01\n",
      "epoch:2  | iteration:1200 | loss:2.0794 | accuracy:0.03\n",
      "epoch:2  | iteration:1300 | loss:2.0794 | accuracy:0.03\n",
      "epoch:2  | iteration:1400 | loss:2.0794 | accuracy:0.03\n",
      "epoch:2  | iteration:1500 | loss:2.0794 | accuracy:0.03\n",
      "epoch:2  | iteration:1600 | loss:2.0794 | accuracy:0.04\n",
      "epoch:2  | iteration:1700 | loss:2.0794 | accuracy:0.03\n",
      "epoch:2  | iteration:1800 | loss:2.0794 | accuracy:0.03\n",
      "epoch:2  | iteration:1900 | loss:2.0794 | accuracy:0.04\n",
      "epoch:2  | iteration:2000 | loss:2.0798 | accuracy:0.04\n",
      "epoch:2  | iteration:2100 | loss:2.0794 | accuracy:0.07\n",
      "epoch:2  | iteration:2200 | loss:2.0794 | accuracy:0.01\n",
      "epoch:2  | iteration:2300 | loss:2.0794 | accuracy:0.07\n",
      "epoch:2  | iteration:2400 | loss:2.0794 | accuracy:0.06\n",
      "epoch:2  | iteration:2500 | loss:2.0794 | accuracy:0.01\n",
      "epoch:2  | iteration:2600 | loss:2.0797 | accuracy:0.05\n",
      "epoch:2  | iteration:2700 | loss:2.0794 | accuracy:0.08\n",
      "epoch:2  | iteration:2800 | loss:2.0768 | accuracy:0.04\n",
      "epoch:2  | iteration:2900 | loss:2.0795 | accuracy:0.17\n",
      "epoch:2  | iteration:3000 | loss:2.0795 | accuracy:0.08\n",
      "epoch:2  | iteration:3100 | loss:2.0794 | accuracy:0.04\n",
      "epoch:2  | iteration:3200 | loss:2.0794 | accuracy:0.04\n",
      "epoch:2  | iteration:3300 | loss:2.0794 | accuracy:0.04\n",
      "epoch:2  | iteration:3400 | loss:2.0791 | accuracy:0.04\n",
      "epoch:2  | iteration:3500 | loss:2.0794 | accuracy:0.13\n",
      "epoch:2  | iteration:3600 | loss:2.0795 | accuracy:0.04\n",
      "epoch:2  | iteration:3700 | loss:2.0794 | accuracy:0.04\n",
      "epoch:2  | iteration:3800 | loss:2.0794 | accuracy:0.00\n",
      "epoch:3  | iteration:0    | loss:2.0794 | accuracy:0.04\n",
      "epoch:3  | iteration:100  | loss:2.0794 | accuracy:0.03\n",
      "epoch:3  | iteration:200  | loss:2.0794 | accuracy:0.07\n",
      "epoch:3  | iteration:300  | loss:2.0794 | accuracy:0.04\n",
      "epoch:3  | iteration:400  | loss:2.0794 | accuracy:0.07\n",
      "epoch:3  | iteration:500  | loss:2.0794 | accuracy:0.06\n",
      "epoch:3  | iteration:600  | loss:2.0794 | accuracy:0.05\n",
      "epoch:3  | iteration:700  | loss:2.0794 | accuracy:0.04\n",
      "epoch:3  | iteration:800  | loss:2.0794 | accuracy:0.17\n",
      "epoch:3  | iteration:900  | loss:2.0794 | accuracy:0.07\n",
      "epoch:3  | iteration:1000 | loss:2.0794 | accuracy:0.11\n",
      "epoch:3  | iteration:1100 | loss:2.0794 | accuracy:0.08\n",
      "epoch:3  | iteration:1200 | loss:2.0794 | accuracy:0.03\n",
      "epoch:3  | iteration:1300 | loss:2.0794 | accuracy:0.03\n",
      "epoch:3  | iteration:1400 | loss:2.0794 | accuracy:0.04\n",
      "epoch:3  | iteration:1500 | loss:2.0794 | accuracy:0.04\n",
      "epoch:3  | iteration:1600 | loss:2.0794 | accuracy:0.04\n",
      "epoch:3  | iteration:1700 | loss:2.0794 | accuracy:0.04\n",
      "epoch:3  | iteration:1800 | loss:2.0794 | accuracy:0.01\n",
      "epoch:3  | iteration:1900 | loss:2.0794 | accuracy:0.11\n",
      "epoch:3  | iteration:2000 | loss:2.0790 | accuracy:0.04\n",
      "epoch:3  | iteration:2100 | loss:2.0794 | accuracy:0.03\n",
      "epoch:3  | iteration:2200 | loss:2.0794 | accuracy:0.18\n",
      "epoch:3  | iteration:2300 | loss:2.0794 | accuracy:0.03\n",
      "epoch:3  | iteration:2400 | loss:2.0794 | accuracy:0.03\n",
      "epoch:3  | iteration:2500 | loss:2.0794 | accuracy:0.03\n",
      "epoch:3  | iteration:2600 | loss:2.0796 | accuracy:0.05\n",
      "epoch:3  | iteration:2700 | loss:2.0794 | accuracy:0.04\n",
      "epoch:3  | iteration:2800 | loss:2.0761 | accuracy:0.03\n",
      "epoch:3  | iteration:2900 | loss:2.0795 | accuracy:0.04\n",
      "epoch:3  | iteration:3000 | loss:2.0794 | accuracy:0.07\n",
      "epoch:3  | iteration:3100 | loss:2.0795 | accuracy:0.10\n",
      "epoch:3  | iteration:3200 | loss:2.0794 | accuracy:0.04\n",
      "epoch:3  | iteration:3300 | loss:2.0794 | accuracy:0.13\n",
      "epoch:3  | iteration:3400 | loss:2.0794 | accuracy:0.04\n",
      "epoch:3  | iteration:3500 | loss:2.0794 | accuracy:0.15\n",
      "epoch:3  | iteration:3600 | loss:2.0795 | accuracy:0.03\n",
      "epoch:3  | iteration:3700 | loss:2.0794 | accuracy:0.03\n",
      "epoch:3  | iteration:3800 | loss:2.0794 | accuracy:0.04\n",
      "epoch:4  | iteration:0    | loss:2.0794 | accuracy:0.01\n",
      "epoch:4  | iteration:100  | loss:2.0794 | accuracy:0.00\n",
      "epoch:4  | iteration:200  | loss:2.0794 | accuracy:0.18\n",
      "epoch:4  | iteration:300  | loss:2.0794 | accuracy:0.02\n",
      "epoch:4  | iteration:400  | loss:2.0794 | accuracy:0.03\n",
      "epoch:4  | iteration:500  | loss:2.0794 | accuracy:0.04\n",
      "epoch:4  | iteration:600  | loss:2.0794 | accuracy:0.12\n",
      "epoch:4  | iteration:700  | loss:2.0794 | accuracy:0.12\n",
      "epoch:4  | iteration:800  | loss:2.0794 | accuracy:0.12\n",
      "epoch:4  | iteration:900  | loss:2.0794 | accuracy:0.12\n",
      "epoch:4  | iteration:1000 | loss:2.0794 | accuracy:0.12\n",
      "epoch:4  | iteration:1100 | loss:2.0794 | accuracy:0.06\n",
      "epoch:4  | iteration:1200 | loss:2.0794 | accuracy:0.07\n",
      "epoch:4  | iteration:1300 | loss:2.0794 | accuracy:0.17\n",
      "epoch:4  | iteration:1400 | loss:2.0794 | accuracy:0.13\n",
      "epoch:4  | iteration:1500 | loss:2.0794 | accuracy:0.14\n",
      "epoch:4  | iteration:1600 | loss:2.0795 | accuracy:0.09\n",
      "epoch:4  | iteration:1700 | loss:2.0794 | accuracy:0.04\n",
      "epoch:4  | iteration:1800 | loss:2.0794 | accuracy:0.07\n",
      "epoch:4  | iteration:1900 | loss:2.0794 | accuracy:0.05\n",
      "epoch:4  | iteration:2000 | loss:2.0795 | accuracy:0.17\n",
      "epoch:4  | iteration:2100 | loss:2.0794 | accuracy:0.07\n",
      "epoch:4  | iteration:2200 | loss:2.0794 | accuracy:0.03\n",
      "epoch:4  | iteration:2300 | loss:2.0794 | accuracy:0.05\n",
      "epoch:4  | iteration:2400 | loss:2.0795 | accuracy:0.12\n",
      "epoch:4  | iteration:2500 | loss:2.0794 | accuracy:0.06\n",
      "epoch:4  | iteration:2600 | loss:2.0795 | accuracy:0.15\n",
      "epoch:4  | iteration:2700 | loss:2.0794 | accuracy:0.10\n",
      "epoch:4  | iteration:2800 | loss:2.0778 | accuracy:0.00\n",
      "epoch:4  | iteration:2900 | loss:2.0794 | accuracy:0.01\n",
      "epoch:4  | iteration:3000 | loss:2.0794 | accuracy:0.08\n",
      "epoch:4  | iteration:3100 | loss:2.0794 | accuracy:0.00\n",
      "epoch:4  | iteration:3200 | loss:2.0794 | accuracy:0.00\n",
      "epoch:4  | iteration:3300 | loss:2.0794 | accuracy:0.04\n",
      "epoch:4  | iteration:3400 | loss:2.0794 | accuracy:0.08\n",
      "epoch:4  | iteration:3500 | loss:2.0794 | accuracy:0.06\n",
      "epoch:4  | iteration:3600 | loss:2.0795 | accuracy:0.11\n",
      "epoch:4  | iteration:3700 | loss:2.0794 | accuracy:0.09\n",
      "epoch:4  | iteration:3800 | loss:2.0794 | accuracy:0.17\n",
      "epoch:5  | iteration:0    | loss:2.0794 | accuracy:0.17\n",
      "epoch:5  | iteration:100  | loss:2.0794 | accuracy:0.04\n",
      "epoch:5  | iteration:200  | loss:2.0794 | accuracy:0.04\n",
      "epoch:5  | iteration:300  | loss:2.0794 | accuracy:0.04\n",
      "epoch:5  | iteration:400  | loss:2.0794 | accuracy:0.05\n",
      "epoch:5  | iteration:500  | loss:2.0794 | accuracy:0.02\n",
      "epoch:5  | iteration:600  | loss:2.0794 | accuracy:0.04\n",
      "epoch:5  | iteration:700  | loss:2.0794 | accuracy:0.04\n",
      "epoch:5  | iteration:800  | loss:2.0794 | accuracy:0.03\n",
      "epoch:5  | iteration:900  | loss:2.0794 | accuracy:0.04\n",
      "epoch:5  | iteration:1000 | loss:2.0794 | accuracy:0.04\n",
      "epoch:5  | iteration:1100 | loss:2.0794 | accuracy:0.01\n",
      "epoch:5  | iteration:1200 | loss:2.0794 | accuracy:0.01\n",
      "epoch:5  | iteration:1300 | loss:2.0794 | accuracy:0.01\n",
      "epoch:5  | iteration:1400 | loss:2.0794 | accuracy:0.01\n",
      "epoch:5  | iteration:1500 | loss:2.0794 | accuracy:0.05\n",
      "epoch:5  | iteration:1600 | loss:2.0795 | accuracy:0.01\n",
      "epoch:5  | iteration:1700 | loss:2.0794 | accuracy:0.01\n",
      "epoch:5  | iteration:1800 | loss:2.0794 | accuracy:0.01\n",
      "epoch:5  | iteration:1900 | loss:2.0794 | accuracy:0.05\n",
      "epoch:5  | iteration:2000 | loss:2.0792 | accuracy:0.08\n",
      "epoch:5  | iteration:2100 | loss:2.0794 | accuracy:0.04\n",
      "epoch:5  | iteration:2200 | loss:2.0794 | accuracy:0.04\n",
      "epoch:5  | iteration:2300 | loss:2.0794 | accuracy:0.01\n",
      "epoch:5  | iteration:2400 | loss:2.0794 | accuracy:0.02\n",
      "epoch:5  | iteration:2500 | loss:2.0794 | accuracy:0.01\n",
      "epoch:5  | iteration:2600 | loss:2.0794 | accuracy:0.01\n",
      "epoch:5  | iteration:2700 | loss:2.0794 | accuracy:0.02\n",
      "epoch:5  | iteration:2800 | loss:2.0767 | accuracy:0.01\n",
      "epoch:5  | iteration:2900 | loss:2.0795 | accuracy:0.05\n",
      "epoch:5  | iteration:3000 | loss:2.0794 | accuracy:0.00\n",
      "epoch:5  | iteration:3100 | loss:2.0795 | accuracy:0.00\n",
      "epoch:5  | iteration:3200 | loss:2.0794 | accuracy:0.05\n",
      "epoch:5  | iteration:3300 | loss:2.0794 | accuracy:0.12\n",
      "epoch:5  | iteration:3400 | loss:2.0793 | accuracy:0.10\n",
      "epoch:5  | iteration:3500 | loss:2.0794 | accuracy:0.06\n",
      "epoch:5  | iteration:3600 | loss:2.0794 | accuracy:0.03\n",
      "epoch:5  | iteration:3700 | loss:2.0794 | accuracy:0.03\n",
      "epoch:5  | iteration:3800 | loss:2.0794 | accuracy:0.03\n",
      "epoch:6  | iteration:0    | loss:2.0794 | accuracy:0.03\n",
      "epoch:6  | iteration:100  | loss:2.0794 | accuracy:0.03\n",
      "epoch:6  | iteration:200  | loss:2.0794 | accuracy:0.05\n",
      "epoch:6  | iteration:300  | loss:2.0794 | accuracy:0.03\n",
      "epoch:6  | iteration:400  | loss:2.0794 | accuracy:0.03\n",
      "epoch:6  | iteration:500  | loss:2.0794 | accuracy:0.03\n",
      "epoch:6  | iteration:600  | loss:2.0794 | accuracy:0.03\n",
      "epoch:6  | iteration:700  | loss:2.0794 | accuracy:0.03\n",
      "epoch:6  | iteration:800  | loss:2.0794 | accuracy:0.03\n",
      "epoch:6  | iteration:900  | loss:2.0794 | accuracy:0.03\n",
      "epoch:6  | iteration:1000 | loss:2.0794 | accuracy:0.03\n",
      "epoch:6  | iteration:1100 | loss:2.0794 | accuracy:0.04\n",
      "epoch:6  | iteration:1200 | loss:2.0794 | accuracy:0.05\n",
      "epoch:6  | iteration:1300 | loss:2.0794 | accuracy:0.02\n",
      "epoch:6  | iteration:1400 | loss:2.0794 | accuracy:0.05\n",
      "epoch:6  | iteration:1500 | loss:2.0795 | accuracy:0.05\n",
      "epoch:6  | iteration:1600 | loss:2.0794 | accuracy:0.05\n",
      "epoch:6  | iteration:1700 | loss:2.0794 | accuracy:0.08\n",
      "epoch:6  | iteration:1800 | loss:2.0794 | accuracy:0.03\n",
      "epoch:6  | iteration:1900 | loss:2.0794 | accuracy:0.00\n",
      "epoch:6  | iteration:2000 | loss:2.0797 | accuracy:0.06\n",
      "epoch:6  | iteration:2100 | loss:2.0794 | accuracy:0.06\n",
      "epoch:6  | iteration:2200 | loss:2.0794 | accuracy:0.05\n",
      "epoch:6  | iteration:2300 | loss:2.0794 | accuracy:0.04\n",
      "epoch:6  | iteration:2400 | loss:2.0794 | accuracy:0.04\n",
      "epoch:6  | iteration:2500 | loss:2.0794 | accuracy:0.03\n",
      "epoch:6  | iteration:2600 | loss:2.0794 | accuracy:0.00\n",
      "epoch:6  | iteration:2700 | loss:2.0794 | accuracy:0.00\n",
      "epoch:6  | iteration:2800 | loss:2.0759 | accuracy:0.00\n",
      "epoch:6  | iteration:2900 | loss:2.0795 | accuracy:0.04\n",
      "epoch:6  | iteration:3000 | loss:2.0794 | accuracy:0.04\n",
      "epoch:6  | iteration:3100 | loss:2.0794 | accuracy:0.04\n",
      "epoch:6  | iteration:3200 | loss:2.0794 | accuracy:0.09\n",
      "epoch:6  | iteration:3300 | loss:2.0794 | accuracy:0.09\n",
      "epoch:6  | iteration:3400 | loss:2.0794 | accuracy:0.01\n",
      "epoch:6  | iteration:3500 | loss:2.0794 | accuracy:0.00\n",
      "epoch:6  | iteration:3600 | loss:2.0795 | accuracy:0.16\n",
      "epoch:6  | iteration:3700 | loss:2.0795 | accuracy:0.08\n",
      "epoch:6  | iteration:3800 | loss:2.0794 | accuracy:0.16\n",
      "epoch:7  | iteration:0    | loss:2.0795 | accuracy:0.17\n",
      "epoch:7  | iteration:100  | loss:2.0795 | accuracy:0.10\n",
      "epoch:7  | iteration:200  | loss:2.0794 | accuracy:0.09\n",
      "epoch:7  | iteration:300  | loss:2.0794 | accuracy:0.07\n",
      "epoch:7  | iteration:400  | loss:2.0794 | accuracy:0.01\n",
      "epoch:7  | iteration:500  | loss:2.0794 | accuracy:0.06\n",
      "epoch:7  | iteration:600  | loss:2.0794 | accuracy:0.06\n",
      "epoch:7  | iteration:700  | loss:2.0794 | accuracy:0.06\n",
      "epoch:7  | iteration:800  | loss:2.0794 | accuracy:0.07\n",
      "epoch:7  | iteration:900  | loss:2.0794 | accuracy:0.03\n",
      "epoch:7  | iteration:1000 | loss:2.0794 | accuracy:0.00\n",
      "epoch:7  | iteration:1100 | loss:2.0794 | accuracy:0.00\n",
      "epoch:7  | iteration:1200 | loss:2.0794 | accuracy:0.08\n",
      "epoch:7  | iteration:1300 | loss:2.0794 | accuracy:0.08\n",
      "epoch:7  | iteration:1400 | loss:2.0794 | accuracy:0.08\n",
      "epoch:7  | iteration:1500 | loss:2.0794 | accuracy:0.04\n",
      "epoch:7  | iteration:1600 | loss:2.0794 | accuracy:0.04\n",
      "epoch:7  | iteration:1700 | loss:2.0794 | accuracy:0.08\n",
      "epoch:7  | iteration:1800 | loss:2.0794 | accuracy:0.03\n",
      "epoch:7  | iteration:1900 | loss:2.0794 | accuracy:0.03\n",
      "epoch:7  | iteration:2000 | loss:2.0794 | accuracy:0.04\n",
      "epoch:7  | iteration:2100 | loss:2.0794 | accuracy:0.03\n",
      "epoch:7  | iteration:2200 | loss:2.0794 | accuracy:0.05\n",
      "epoch:7  | iteration:2300 | loss:2.0794 | accuracy:0.04\n",
      "epoch:7  | iteration:2400 | loss:2.0794 | accuracy:0.05\n",
      "epoch:7  | iteration:2500 | loss:2.0794 | accuracy:0.03\n",
      "epoch:7  | iteration:2600 | loss:2.0794 | accuracy:0.03\n",
      "epoch:7  | iteration:2700 | loss:2.0794 | accuracy:0.00\n",
      "epoch:7  | iteration:2800 | loss:2.0759 | accuracy:0.04\n",
      "epoch:7  | iteration:2900 | loss:2.0795 | accuracy:0.00\n",
      "epoch:7  | iteration:3000 | loss:2.0794 | accuracy:0.09\n",
      "epoch:7  | iteration:3100 | loss:2.0794 | accuracy:0.03\n",
      "epoch:7  | iteration:3200 | loss:2.0794 | accuracy:0.03\n",
      "epoch:7  | iteration:3300 | loss:2.0794 | accuracy:0.03\n",
      "epoch:7  | iteration:3400 | loss:2.0794 | accuracy:0.07\n",
      "epoch:7  | iteration:3500 | loss:2.0794 | accuracy:0.04\n",
      "epoch:7  | iteration:3600 | loss:2.0795 | accuracy:0.03\n",
      "epoch:7  | iteration:3700 | loss:2.0794 | accuracy:0.00\n",
      "epoch:7  | iteration:3800 | loss:2.0794 | accuracy:0.11\n",
      "epoch:8  | iteration:0    | loss:2.0794 | accuracy:0.11\n",
      "epoch:8  | iteration:100  | loss:2.0794 | accuracy:0.08\n",
      "epoch:8  | iteration:200  | loss:2.0794 | accuracy:0.09\n",
      "epoch:8  | iteration:300  | loss:2.0794 | accuracy:0.03\n",
      "epoch:8  | iteration:400  | loss:2.0795 | accuracy:0.03\n",
      "epoch:8  | iteration:500  | loss:2.0795 | accuracy:0.01\n",
      "epoch:8  | iteration:600  | loss:2.0794 | accuracy:0.03\n",
      "epoch:8  | iteration:700  | loss:2.0794 | accuracy:0.03\n",
      "epoch:8  | iteration:800  | loss:2.0794 | accuracy:0.03\n",
      "epoch:8  | iteration:900  | loss:2.0794 | accuracy:0.00\n",
      "epoch:8  | iteration:1000 | loss:2.0795 | accuracy:0.00\n",
      "epoch:8  | iteration:1100 | loss:2.0794 | accuracy:0.11\n",
      "epoch:8  | iteration:1200 | loss:2.0794 | accuracy:0.03\n",
      "epoch:8  | iteration:1300 | loss:2.0794 | accuracy:0.08\n",
      "epoch:8  | iteration:1400 | loss:2.0794 | accuracy:0.03\n",
      "epoch:8  | iteration:1500 | loss:2.0795 | accuracy:0.03\n",
      "epoch:8  | iteration:1600 | loss:2.0793 | accuracy:0.10\n",
      "epoch:8  | iteration:1700 | loss:2.0794 | accuracy:0.12\n",
      "epoch:8  | iteration:1800 | loss:2.0794 | accuracy:0.00\n",
      "epoch:8  | iteration:1900 | loss:2.0794 | accuracy:0.00\n",
      "epoch:8  | iteration:2000 | loss:2.0796 | accuracy:0.03\n",
      "epoch:8  | iteration:2100 | loss:2.0794 | accuracy:0.03\n",
      "epoch:8  | iteration:2200 | loss:2.0794 | accuracy:0.05\n",
      "epoch:8  | iteration:2300 | loss:2.0794 | accuracy:0.00\n",
      "epoch:8  | iteration:2400 | loss:2.0795 | accuracy:0.03\n",
      "epoch:8  | iteration:2500 | loss:2.0794 | accuracy:0.09\n",
      "epoch:8  | iteration:2600 | loss:2.0794 | accuracy:0.09\n",
      "epoch:8  | iteration:2700 | loss:2.0794 | accuracy:0.09\n",
      "epoch:8  | iteration:2800 | loss:2.0761 | accuracy:0.03\n",
      "epoch:8  | iteration:2900 | loss:2.0795 | accuracy:0.08\n",
      "epoch:8  | iteration:3000 | loss:2.0794 | accuracy:0.10\n",
      "epoch:8  | iteration:3100 | loss:2.0794 | accuracy:0.10\n",
      "epoch:8  | iteration:3200 | loss:2.0794 | accuracy:0.10\n",
      "epoch:8  | iteration:3300 | loss:2.0794 | accuracy:0.08\n",
      "epoch:8  | iteration:3400 | loss:2.0795 | accuracy:0.11\n",
      "epoch:8  | iteration:3500 | loss:2.0794 | accuracy:0.10\n",
      "epoch:8  | iteration:3600 | loss:2.0795 | accuracy:0.11\n",
      "epoch:8  | iteration:3700 | loss:2.0794 | accuracy:0.08\n",
      "epoch:8  | iteration:3800 | loss:2.0794 | accuracy:0.04\n",
      "epoch:9  | iteration:0    | loss:2.0794 | accuracy:0.04\n",
      "epoch:9  | iteration:100  | loss:2.0794 | accuracy:0.04\n",
      "epoch:9  | iteration:200  | loss:2.0794 | accuracy:0.04\n",
      "epoch:9  | iteration:300  | loss:2.0794 | accuracy:0.10\n",
      "epoch:9  | iteration:400  | loss:2.0794 | accuracy:0.14\n",
      "epoch:9  | iteration:500  | loss:2.0794 | accuracy:0.05\n",
      "epoch:9  | iteration:600  | loss:2.0794 | accuracy:0.08\n",
      "epoch:9  | iteration:700  | loss:2.0794 | accuracy:0.08\n",
      "epoch:9  | iteration:800  | loss:2.0794 | accuracy:0.08\n",
      "epoch:9  | iteration:900  | loss:2.0794 | accuracy:0.08\n",
      "epoch:9  | iteration:1000 | loss:2.0794 | accuracy:0.08\n",
      "epoch:9  | iteration:1100 | loss:2.0794 | accuracy:0.08\n",
      "epoch:9  | iteration:1200 | loss:2.0794 | accuracy:0.08\n",
      "epoch:9  | iteration:1300 | loss:2.0794 | accuracy:0.08\n",
      "epoch:9  | iteration:1400 | loss:2.0794 | accuracy:0.08\n",
      "epoch:9  | iteration:1500 | loss:2.0794 | accuracy:0.08\n",
      "epoch:9  | iteration:1600 | loss:2.0794 | accuracy:0.08\n",
      "epoch:9  | iteration:1700 | loss:2.0794 | accuracy:0.08\n",
      "epoch:9  | iteration:1800 | loss:2.0794 | accuracy:0.08\n",
      "epoch:9  | iteration:1900 | loss:2.0794 | accuracy:0.03\n",
      "epoch:9  | iteration:2000 | loss:2.0794 | accuracy:0.03\n",
      "epoch:9  | iteration:2100 | loss:2.0794 | accuracy:0.08\n",
      "epoch:9  | iteration:2200 | loss:2.0794 | accuracy:0.03\n",
      "epoch:9  | iteration:2300 | loss:2.0794 | accuracy:0.03\n",
      "epoch:9  | iteration:2400 | loss:2.0794 | accuracy:0.11\n",
      "epoch:9  | iteration:2500 | loss:2.0794 | accuracy:0.04\n",
      "epoch:9  | iteration:2600 | loss:2.0794 | accuracy:0.04\n",
      "epoch:9  | iteration:2700 | loss:2.0794 | accuracy:0.04\n",
      "epoch:9  | iteration:2800 | loss:2.0761 | accuracy:0.03\n",
      "epoch:9  | iteration:2900 | loss:2.0795 | accuracy:0.04\n",
      "epoch:9  | iteration:3000 | loss:2.0794 | accuracy:0.04\n",
      "epoch:9  | iteration:3100 | loss:2.0795 | accuracy:0.04\n",
      "epoch:9  | iteration:3200 | loss:2.0794 | accuracy:0.04\n",
      "epoch:9  | iteration:3300 | loss:2.0794 | accuracy:0.04\n",
      "epoch:9  | iteration:3400 | loss:2.0794 | accuracy:0.03\n",
      "epoch:9  | iteration:3500 | loss:2.0794 | accuracy:0.03\n",
      "epoch:9  | iteration:3600 | loss:2.0795 | accuracy:0.03\n",
      "epoch:9  | iteration:3700 | loss:2.0795 | accuracy:0.03\n",
      "epoch:9  | iteration:3800 | loss:2.0794 | accuracy:0.03\n"
     ]
    }
   ],
   "source": [
    "global_step = 0\n",
    "for epoch in range(EPOCHS):\n",
    "    for i, (X, y) in enumerate(train_loader):\n",
    "        output = net(X.unsqueeze(0)).squeeze()\n",
    "        loss = criterion(output, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        global_step += 1\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            net.eval()\n",
    "            test_pred = net(X_val.unsqueeze(0)).squeeze().argmax(dim = 1)\n",
    "            accuracy = accuracy_score(y_val, test_pred)\n",
    "            print('epoch:{:<2d} | iteration:{:<4d} | loss:{:<6.4f} | accuracy:{:<4.2f}'.format(epoch, i, loss, accuracy))\n",
    "            writer.add_scalar('loss_train', loss, global_step)\n",
    "            writer.add_scalar('accuracy_val', accuracy, global_step)\n",
    "            writer.add_scalar('lr', optimizer.state_dict()['param_groups'][0]['lr'], global_step)\n",
    "            net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}