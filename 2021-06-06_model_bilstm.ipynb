{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torchsummary import summary\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import precision_score, confusion_matrix, f1_score, accuracy_score, recall_score, classification_report\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "source": [
    "# Setting"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"dark_background\")"
   ]
  },
  {
   "source": [
    "# Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, feature_size, hidden_size, lstm_layer, dropout = 0.2, num_class = 8):\n",
    "        super(BiLSTM, self).__init__()\n",
    "        self.input_size = feature_size\n",
    "        self.hidden_dim = hidden_size\n",
    "        self.dropout = nn.Dropout(p = dropout)\n",
    "        self.lstm = nn.LSTM(input_size = self.input_size, \n",
    "                            hidden_size = hidden_size,\n",
    "                            num_layers = lstm_layer,\n",
    "                            dropout = dropout,\n",
    "                            bidirectional = True)\n",
    "        self.hidden2label = nn.Linear(hidden_size*2, num_class)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        label_space = self.hidden2label(lstm_out)\n",
    "        label_scores = nn.Softmax(dim = 1)(label_space)\n",
    "\n",
    "        return label_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = torch.rand([1, 1000, 32])\n",
    "net = BiLSTM(feature_size = 32, hidden_size = 128, lstm_layer = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 1000, 8])"
      ]
     },
     "metadata": {},
     "execution_count": 358
    }
   ],
   "source": [
    "pred = net(sample)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = list(pred.flatten().detach().numpy())\n",
    "# plt.hist(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1, 5, 5, 1, 5, 8, 1, 2, 2, 7, 7, 5, 5, 5, 5, 7, 2, 8, 2, 4, 1, 1,\n",
       "       3, 4, 8, 3, 8, 6, 2, 3, 7, 3, 8, 7, 4, 2, 1, 6, 1, 1, 5, 4, 6, 4,\n",
       "       5, 6, 6, 6, 4, 7, 4, 4, 6, 7, 4, 2, 5, 2, 2, 3, 6, 4, 7, 7, 3, 7,\n",
       "       3, 1, 7, 5, 2, 4, 8, 5, 4, 5, 8, 1, 2, 2, 5, 2, 8, 8, 7, 2, 6, 7,\n",
       "       1, 1, 8, 6, 1, 4, 5, 7, 1, 8, 5, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 361
    }
   ],
   "source": [
    "# predicted label example\n",
    "(pred.squeeze().detach().numpy().argmax(axis = 1) + 1)[:100]"
   ]
  },
  {
   "source": [
    "# Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('data/mid_res/20210526_data_df.csv')\n",
    "val_df = pd.read_csv('data/mid_res/20210526_val_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_drop_x = ['time', 'label']\n",
    "col_label = 'label'\n",
    "col_drop = ['latitude',\n",
    " 'longitude',\n",
    " 'altitude',\n",
    " 'time_dlt',\n",
    " 'valid_dlt',\n",
    " 'east',\n",
    " 'north',\n",
    " 'east_dlt',\n",
    " 'north_dlt',\n",
    " 'east_speed',\n",
    " 'north_speed',\n",
    " 'cells_ctype_mode',\n",
    " 'speed_dif',\n",
    " 'speed_dlt',\n",
    " 'speed'\n",
    " ]\n",
    "X_train, y_train = data_df.drop(col_drop_x + col_drop, axis = 1).fillna(0).copy(), data_df[col_label].copy()\n",
    "X_train = X_train.apply(lambda x: (x-min(x))/(max(x)-min(x)), axis = 0)\n",
    "y_train -= 1\n",
    "\n",
    "X_val, y_val = val_df.drop(col_drop_x + col_drop, axis = 1).fillna(0).copy(), val_df[col_label].copy()\n",
    "X_val = X_val.apply(lambda x: (x-min(x))/(max(x)-min(x)), axis = 0)\n",
    "y_val -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TMR_Dataset(Dataset):\n",
    "    def __init__(self, x_array, label):\n",
    "        super().__init__()\n",
    "        self.len, self.feature_size = x_array.shape\n",
    "        self.data = x_array\n",
    "        self.data = torch.tensor(self.data).float()\n",
    "        self.label = label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.data[idx,:], self.label[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1024\n",
    "EPOCHS = 10\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = TMR_Dataset(np.array(X_train), y_train)\n",
    "train_loader = DataLoader(data, batch_size = BATCH_SIZE, shuffle = False)\n",
    "X_val = torch.tensor(np.array(X_val), dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = BiLSTM(feature_size = 32, hidden_size = 4, lstm_layer = 4)\n",
    "# X, y = next(iter(train_loader))\n",
    "# net(X.unsqueeze(0)).squeeze().argmax(dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(log_dir = 'log', comment = \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = BiLSTM(feature_size = 32, hidden_size = 128, lstm_layer = 4, dropout = 0.75, num_class = 8).to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr = LR, weight_decay = 0.95)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([6, 6, 6,  ..., 6, 6, 6])"
      ]
     },
     "metadata": {},
     "execution_count": 352
    }
   ],
   "source": [
    "net(X_val.unsqueeze(0)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch:0  | iteration:0    | loss:2.0795 | accuracy_val:0.16 | accuracy_train:0.13\n",
      "epoch:0  | iteration:100  | loss:2.0795 | accuracy_val:0.15 | accuracy_train:0.14\n",
      "epoch:0  | iteration:200  | loss:2.0795 | accuracy_val:0.15 | accuracy_train:0.00\n",
      "epoch:0  | iteration:300  | loss:2.0795 | accuracy_val:0.15 | accuracy_train:0.00\n",
      "epoch:0  | iteration:400  | loss:2.0795 | accuracy_val:0.15 | accuracy_train:0.00\n",
      "epoch:0  | iteration:500  | loss:2.0795 | accuracy_val:0.15 | accuracy_train:0.00\n",
      "epoch:0  | iteration:600  | loss:2.0795 | accuracy_val:0.15 | accuracy_train:0.00\n",
      "epoch:0  | iteration:700  | loss:2.0795 | accuracy_val:0.15 | accuracy_train:0.11\n",
      "epoch:0  | iteration:800  | loss:2.0795 | accuracy_val:0.15 | accuracy_train:0.00\n",
      "epoch:0  | iteration:900  | loss:2.0795 | accuracy_val:0.15 | accuracy_train:0.00\n",
      "epoch:1  | iteration:0    | loss:2.0795 | accuracy_val:0.15 | accuracy_train:0.00\n",
      "epoch:1  | iteration:100  | loss:2.0795 | accuracy_val:0.15 | accuracy_train:0.00\n",
      "epoch:1  | iteration:200  | loss:2.0795 | accuracy_val:0.15 | accuracy_train:0.00\n",
      "epoch:1  | iteration:300  | loss:2.0795 | accuracy_val:0.15 | accuracy_train:0.00\n",
      "epoch:1  | iteration:400  | loss:2.0795 | accuracy_val:0.15 | accuracy_train:0.00\n",
      "epoch:1  | iteration:500  | loss:2.0795 | accuracy_val:0.15 | accuracy_train:0.00\n",
      "epoch:1  | iteration:600  | loss:2.0795 | accuracy_val:0.15 | accuracy_train:0.00\n",
      "epoch:1  | iteration:700  | loss:2.0795 | accuracy_val:0.15 | accuracy_train:0.11\n",
      "epoch:1  | iteration:800  | loss:2.0795 | accuracy_val:0.15 | accuracy_train:0.00\n",
      "epoch:1  | iteration:900  | loss:2.0795 | accuracy_val:0.15 | accuracy_train:0.00\n",
      "epoch:2  | iteration:0    | loss:2.0795 | accuracy_val:0.15 | accuracy_train:0.00\n",
      "epoch:2  | iteration:100  | loss:2.0795 | accuracy_val:0.15 | accuracy_train:0.00\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-348-bd76272e14a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mtest_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0maccuracy_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0maccuracy_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/shl_nn/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-265-4666cbaf0a21>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mlabel_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden2label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mlabel_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/shl_nn/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/shl_nn/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_packed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/shl_nn/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_tensor\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0munsorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/shl_nn/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_impl\u001b[0;34m(self, input, hx, batch_sizes, max_batch_size, sorted_indices)\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m             result = _VF.lstm(input, hx, self._get_flat_weights(), self.bias, self.num_layers,\n\u001b[0;32m--> 526\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._get_flat_weights(), self.bias,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "global_step = 0\n",
    "for epoch in range(EPOCHS):\n",
    "    for i, (X, y) in enumerate(train_loader):\n",
    "        output = net(X.unsqueeze(0)).squeeze()\n",
    "        loss = criterion(output, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        global_step += 1\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            net.eval()\n",
    "            test_pred = net(X_val.unsqueeze(0)).squeeze().argmax(dim = 1)\n",
    "            accuracy_train = accuracy_score(y, output.argmax(dim = 1))\n",
    "            accuracy_val = accuracy_score(y_val, test_pred)\n",
    "            print('epoch:{:<2d} | iteration:{:<4d} | loss:{:<6.4f} | accuracy_val:{:<4.2f} | accuracy_train:{:<4.2f}'.format(epoch, i, loss, accuracy_val, accuracy_train))\n",
    "\n",
    "            # summary writer\n",
    "            writer.add_scalar('loss_train', loss, global_step)\n",
    "            writer.add_scalar('accuracy/train', accuracy_train, global_step)\n",
    "            writer.add_scalar('accuracy/val', accuracy_val, global_step)\n",
    "            writer.add_scalar('lr', optimizer.state_dict()['param_groups'][0]['lr'], global_step)\n",
    "            net.train()"
   ]
  },
  {
   "source": [
    "# Test (Tiny DataSet)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "38310"
      ]
     },
     "metadata": {},
     "execution_count": 252
    }
   ],
   "source": [
    "global_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = TMR_Dataset(np.array(X_train)[:20,:], y_train[:20] - 1)\n",
    "data = TMR_Dataset(np.array(X_train)[:20,:], [1]*10 + [0]*10)\n",
    "train_loader = DataLoader(data, batch_size = 20, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = BiLSTM(feature_size = 32, hidden_size = 64, lstm_layer = 4).to(device)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr = LR)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = 0\n",
    "accs = []\n",
    "for epoch in range(1000):\n",
    "    output = net(X.unsqueeze(0)).squeeze()\n",
    "    loss = criterion(output, y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    pred = output.argmax(dim = 1)\n",
    "    accuracy = accuracy_score(y, pred)\n",
    "    # print(epoch, accuracy)\n",
    "    accs.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbe94367150>]"
      ]
     },
     "metadata": {},
     "execution_count": 238
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 372.103125 248.518125\" width=\"372.103125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-06-02T16:18:31.353675</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.4.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 372.103125 248.518125 \nL 372.103125 0 \nL 0 0 \nz\n\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 30.103125 224.64 \nL 364.903125 224.64 \nL 364.903125 7.2 \nL 30.103125 7.2 \nz\n\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"mc15fdba700\" style=\"stroke:#ffffff;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"45.321307\" xlink:href=\"#mc15fdba700\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g style=\"fill:#ffffff;\" transform=\"translate(42.140057 239.238438)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" id=\"DejaVuSans-30\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"106.254968\" xlink:href=\"#mc15fdba700\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 200 -->\n      <g style=\"fill:#ffffff;\" transform=\"translate(96.711218 239.238438)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" id=\"DejaVuSans-32\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"167.188629\" xlink:href=\"#mc15fdba700\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 400 -->\n      <g style=\"fill:#ffffff;\" transform=\"translate(157.644879 239.238438)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" id=\"DejaVuSans-34\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"228.12229\" xlink:href=\"#mc15fdba700\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 600 -->\n      <g style=\"fill:#ffffff;\" transform=\"translate(218.57854 239.238438)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" id=\"DejaVuSans-36\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"289.055951\" xlink:href=\"#mc15fdba700\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 800 -->\n      <g style=\"fill:#ffffff;\" transform=\"translate(279.512201 239.238438)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" id=\"DejaVuSans-38\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-38\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"349.989611\" xlink:href=\"#mc15fdba700\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 1000 -->\n      <g style=\"fill:#ffffff;\" transform=\"translate(337.264611 239.238438)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" id=\"DejaVuSans-31\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m01f200b49d\" style=\"stroke:#ffffff;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m01f200b49d\" y=\"199.550769\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0.4 -->\n      <g style=\"fill:#ffffff;\" transform=\"translate(7.2 203.349988)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" id=\"DejaVuSans-2e\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-34\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m01f200b49d\" y=\"169.13958\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.5 -->\n      <g style=\"fill:#ffffff;\" transform=\"translate(7.2 172.938799)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" id=\"DejaVuSans-35\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m01f200b49d\" y=\"138.728392\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.6 -->\n      <g style=\"fill:#ffffff;\" transform=\"translate(7.2 142.52761)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-36\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m01f200b49d\" y=\"108.317203\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.7 -->\n      <g style=\"fill:#ffffff;\" transform=\"translate(7.2 112.116422)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 525 4666 \nL 3525 4666 \nL 3525 4397 \nL 1831 0 \nL 1172 0 \nL 2766 4134 \nL 525 4134 \nL 525 4666 \nz\n\" id=\"DejaVuSans-37\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-37\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m01f200b49d\" y=\"77.906014\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.8 -->\n      <g style=\"fill:#ffffff;\" transform=\"translate(7.2 81.705233)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-38\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m01f200b49d\" y=\"47.494825\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.9 -->\n      <g style=\"fill:#ffffff;\" transform=\"translate(7.2 51.294044)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 703 97 \nL 703 672 \nQ 941 559 1184 500 \nQ 1428 441 1663 441 \nQ 2288 441 2617 861 \nQ 2947 1281 2994 2138 \nQ 2813 1869 2534 1725 \nQ 2256 1581 1919 1581 \nQ 1219 1581 811 2004 \nQ 403 2428 403 3163 \nQ 403 3881 828 4315 \nQ 1253 4750 1959 4750 \nQ 2769 4750 3195 4129 \nQ 3622 3509 3622 2328 \nQ 3622 1225 3098 567 \nQ 2575 -91 1691 -91 \nQ 1453 -91 1209 -44 \nQ 966 3 703 97 \nz\nM 1959 2075 \nQ 2384 2075 2632 2365 \nQ 2881 2656 2881 3163 \nQ 2881 3666 2632 3958 \nQ 2384 4250 1959 4250 \nQ 1534 4250 1286 3958 \nQ 1038 3666 1038 3163 \nQ 1038 2656 1286 2365 \nQ 1534 2075 1959 2075 \nz\n\" id=\"DejaVuSans-39\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-39\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"fill:#ffffff;stroke:#ffffff;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m01f200b49d\" y=\"17.083636\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 1.0 -->\n      <g style=\"fill:#ffffff;\" transform=\"translate(7.2 20.882855)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-2e\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_14\">\n    <path clip-path=\"url(#p851ac0055e)\" d=\"M 45.321307 123.522797 \nL 45.625975 184.345175 \nL 45.930643 138.728392 \nL 46.235312 214.756364 \nL 46.53998 199.550769 \nL 46.844648 123.522797 \nL 47.149317 199.550769 \nL 47.758653 138.728392 \nL 48.36799 108.317203 \nL 48.672658 199.550769 \nL 48.977326 77.906014 \nL 49.281995 123.522797 \nL 49.586663 138.728392 \nL 49.891331 199.550769 \nL 50.500668 169.13958 \nL 50.805336 108.317203 \nL 51.110005 138.728392 \nL 51.414673 108.317203 \nL 51.719341 108.317203 \nL 52.02401 123.522797 \nL 52.328678 153.933986 \nL 52.633346 138.728392 \nL 52.938014 138.728392 \nL 53.242683 153.933986 \nL 53.852019 153.933986 \nL 54.156688 123.522797 \nL 54.461356 62.70042 \nL 54.766024 62.70042 \nL 55.070693 93.111608 \nL 55.375361 93.111608 \nL 55.680029 138.728392 \nL 55.984697 77.906014 \nL 56.289366 108.317203 \nL 56.898702 32.289231 \nL 57.203371 47.494825 \nL 57.508039 93.111608 \nL 57.812707 62.70042 \nL 58.117376 123.522797 \nL 58.422044 123.522797 \nL 58.726712 138.728392 \nL 59.031381 93.111608 \nL 59.336049 93.111608 \nL 59.640717 77.906014 \nL 59.945385 32.289231 \nL 60.554722 123.522797 \nL 60.85939 123.522797 \nL 61.164059 108.317203 \nL 61.468727 47.494825 \nL 61.773395 62.70042 \nL 62.6874 62.70042 \nL 62.992068 47.494825 \nL 63.296737 77.906014 \nL 63.601405 32.289231 \nL 63.906073 62.70042 \nL 64.51541 32.289231 \nL 64.820078 32.289231 \nL 65.734083 77.906014 \nL 66.038752 123.522797 \nL 66.34342 123.522797 \nL 66.648088 138.728392 \nL 66.952756 108.317203 \nL 67.257425 123.522797 \nL 67.562093 93.111608 \nL 67.866761 77.906014 \nL 68.17143 17.083636 \nL 68.780766 77.906014 \nL 69.085435 47.494825 \nL 69.390103 47.494825 \nL 69.694771 108.317203 \nL 69.999439 62.70042 \nL 70.304108 62.70042 \nL 70.608776 32.289231 \nL 70.913444 47.494825 \nL 71.218113 32.289231 \nL 71.522781 77.906014 \nL 72.132118 47.494825 \nL 72.436786 47.494825 \nL 72.741454 32.289231 \nL 73.046123 47.494825 \nL 73.350791 77.906014 \nL 73.655459 32.289231 \nL 74.264796 32.289231 \nL 74.569464 62.70042 \nL 74.874132 62.70042 \nL 75.178801 32.289231 \nL 75.483469 47.494825 \nL 75.788137 32.289231 \nL 76.092806 93.111608 \nL 76.397474 62.70042 \nL 76.702142 77.906014 \nL 77.006811 47.494825 \nL 77.311479 62.70042 \nL 77.616147 47.494825 \nL 77.920815 47.494825 \nL 78.225484 32.289231 \nL 78.530152 32.289231 \nL 78.83482 77.906014 \nL 79.139489 47.494825 \nL 79.748825 47.494825 \nL 80.053494 17.083636 \nL 80.358162 47.494825 \nL 80.66283 62.70042 \nL 80.967498 62.70042 \nL 81.576835 32.289231 \nL 81.881503 62.70042 \nL 82.49084 32.289231 \nL 82.795508 47.494825 \nL 83.404845 47.494825 \nL 83.709513 62.70042 \nL 84.014182 32.289231 \nL 84.31885 17.083636 \nL 84.623518 62.70042 \nL 85.232855 32.289231 \nL 85.842191 32.289231 \nL 86.14686 47.494825 \nL 86.451528 47.494825 \nL 86.756196 32.289231 \nL 87.060865 32.289231 \nL 87.365533 77.906014 \nL 87.670201 32.289231 \nL 88.279538 32.289231 \nL 88.584206 47.494825 \nL 88.888874 32.289231 \nL 89.802879 32.289231 \nL 90.107548 47.494825 \nL 90.412216 47.494825 \nL 90.716884 32.289231 \nL 91.326221 32.289231 \nL 91.630889 47.494825 \nL 91.935557 32.289231 \nL 92.240226 47.494825 \nL 92.544894 32.289231 \nL 92.849562 62.70042 \nL 93.154231 32.289231 \nL 93.458899 47.494825 \nL 93.763567 17.083636 \nL 94.068236 47.494825 \nL 94.677572 47.494825 \nL 94.98224 17.083636 \nL 95.591577 47.494825 \nL 95.896245 32.289231 \nL 96.200914 32.289231 \nL 96.505582 17.083636 \nL 96.81025 32.289231 \nL 97.114919 17.083636 \nL 97.419587 32.289231 \nL 98.63826 32.289231 \nL 98.942928 17.083636 \nL 99.247597 47.494825 \nL 99.856933 17.083636 \nL 100.161602 47.494825 \nL 100.46627 32.289231 \nL 100.770938 47.494825 \nL 101.075607 32.289231 \nL 101.380275 32.289231 \nL 101.684943 47.494825 \nL 101.989611 32.289231 \nL 102.29428 47.494825 \nL 102.598948 32.289231 \nL 104.426958 32.289231 \nL 104.731626 47.494825 \nL 105.036295 32.289231 \nL 105.340963 32.289231 \nL 105.645631 47.494825 \nL 105.950299 47.494825 \nL 106.254968 17.083636 \nL 106.559636 47.494825 \nL 106.864304 32.289231 \nL 108.082978 32.289231 \nL 108.387646 47.494825 \nL 108.692314 32.289231 \nL 108.996982 47.494825 \nL 109.301651 17.083636 \nL 109.606319 32.289231 \nL 109.910987 32.289231 \nL 110.215656 17.083636 \nL 110.520324 32.289231 \nL 111.129661 32.289231 \nL 111.434329 17.083636 \nL 111.738997 32.289231 \nL 112.043666 32.289231 \nL 112.348334 47.494825 \nL 112.95767 47.494825 \nL 113.262339 32.289231 \nL 113.567007 47.494825 \nL 113.871675 32.289231 \nL 114.176344 32.289231 \nL 114.481012 47.494825 \nL 114.78568 47.494825 \nL 115.090349 32.289231 \nL 115.395017 47.494825 \nL 115.699685 32.289231 \nL 118.4417 32.289231 \nL 118.746368 47.494825 \nL 119.355705 47.494825 \nL 119.660373 32.289231 \nL 120.574378 32.289231 \nL 120.879046 47.494825 \nL 121.183715 47.494825 \nL 121.488383 32.289231 \nL 122.707056 32.289231 \nL 123.011725 47.494825 \nL 123.316393 32.289231 \nL 123.925729 32.289231 \nL 124.230398 47.494825 \nL 124.535066 32.289231 \nL 124.839734 47.494825 \nL 125.144403 47.494825 \nL 125.449071 32.289231 \nL 125.753739 47.494825 \nL 126.058408 32.289231 \nL 127.277081 32.289231 \nL 127.581749 47.494825 \nL 127.886417 32.289231 \nL 128.495754 32.289231 \nL 128.800422 47.494825 \nL 129.105091 32.289231 \nL 129.714427 32.289231 \nL 130.019096 17.083636 \nL 130.323764 32.289231 \nL 131.237769 32.289231 \nL 131.542437 17.083636 \nL 131.847105 32.289231 \nL 132.76111 32.289231 \nL 133.065779 17.083636 \nL 133.675115 47.494825 \nL 134.284452 47.494825 \nL 134.58912 32.289231 \nL 135.198457 32.289231 \nL 135.503125 62.70042 \nL 135.807793 47.494825 \nL 136.41713 47.494825 \nL 136.721798 32.289231 \nL 137.635803 32.289231 \nL 138.24514 62.70042 \nL 138.854476 32.289231 \nL 140.07315 32.289231 \nL 140.377818 47.494825 \nL 140.682486 32.289231 \nL 140.987154 32.289231 \nL 141.291823 47.494825 \nL 141.596491 17.083636 \nL 141.901159 32.289231 \nL 142.205828 32.289231 \nL 142.510496 47.494825 \nL 142.815164 32.289231 \nL 143.424501 32.289231 \nL 143.729169 47.494825 \nL 144.033838 32.289231 \nL 147.080521 32.289231 \nL 147.385189 17.083636 \nL 147.689857 32.289231 \nL 148.90853 32.289231 \nL 149.213199 17.083636 \nL 149.517867 47.494825 \nL 149.822535 32.289231 \nL 151.041209 32.289231 \nL 151.345877 47.494825 \nL 151.650545 47.494825 \nL 151.955213 32.289231 \nL 152.259882 47.494825 \nL 152.56455 47.494825 \nL 152.869218 32.289231 \nL 153.173887 47.494825 \nL 153.478555 47.494825 \nL 153.783223 32.289231 \nL 154.087892 47.494825 \nL 154.39256 32.289231 \nL 154.697228 32.289231 \nL 155.001896 17.083636 \nL 155.306565 32.289231 \nL 155.915901 32.289231 \nL 156.22057 47.494825 \nL 156.525238 32.289231 \nL 156.829906 32.289231 \nL 157.134575 47.494825 \nL 157.439243 32.289231 \nL 158.657916 32.289231 \nL 158.962584 47.494825 \nL 159.267253 32.289231 \nL 159.571921 32.289231 \nL 159.876589 17.083636 \nL 160.181258 32.289231 \nL 161.399931 32.289231 \nL 161.704599 47.494825 \nL 162.009268 47.494825 \nL 162.313936 32.289231 \nL 162.618604 32.289231 \nL 162.923272 17.083636 \nL 163.227941 32.289231 \nL 164.446614 32.289231 \nL 164.751282 47.494825 \nL 165.055951 47.494825 \nL 165.360619 32.289231 \nL 165.665287 47.494825 \nL 165.969955 47.494825 \nL 166.274624 32.289231 \nL 167.188629 32.289231 \nL 167.493297 47.494825 \nL 167.797965 47.494825 \nL 168.102634 32.289231 \nL 169.625975 32.289231 \nL 170.235312 62.70042 \nL 170.53998 62.70042 \nL 171.149317 32.289231 \nL 172.672658 32.289231 \nL 172.977326 47.494825 \nL 173.891331 47.494825 \nL 174.196 32.289231 \nL 174.500668 62.70042 \nL 174.805336 32.289231 \nL 176.328678 32.289231 \nL 176.633346 47.494825 \nL 176.938014 32.289231 \nL 177.547351 32.289231 \nL 177.852019 47.494825 \nL 178.156688 32.289231 \nL 178.461356 47.494825 \nL 178.766024 32.289231 \nL 180.898702 32.289231 \nL 181.203371 47.494825 \nL 181.812707 47.494825 \nL 182.117376 32.289231 \nL 182.422044 32.289231 \nL 182.726712 47.494825 \nL 183.031381 17.083636 \nL 183.640717 47.494825 \nL 183.945385 17.083636 \nL 184.250054 17.083636 \nL 184.85939 47.494825 \nL 185.164059 32.289231 \nL 185.468727 47.494825 \nL 186.382732 47.494825 \nL 186.6874 17.083636 \nL 186.992068 17.083636 \nL 187.296737 32.289231 \nL 187.906073 32.289231 \nL 188.210742 47.494825 \nL 188.51541 47.494825 \nL 188.820078 32.289231 \nL 190.038752 32.289231 \nL 190.34342 47.494825 \nL 190.648088 32.289231 \nL 190.952756 32.289231 \nL 191.257425 47.494825 \nL 191.562093 32.289231 \nL 191.866761 47.494825 \nL 192.17143 17.083636 \nL 192.476098 47.494825 \nL 192.780766 47.494825 \nL 193.085435 32.289231 \nL 194.608776 32.289231 \nL 194.913444 47.494825 \nL 195.218113 32.289231 \nL 195.522781 47.494825 \nL 195.827449 47.494825 \nL 196.132118 17.083636 \nL 196.436786 32.289231 \nL 196.741454 32.289231 \nL 197.046123 17.083636 \nL 197.655459 17.083636 \nL 197.960127 32.289231 \nL 198.264796 32.289231 \nL 198.569464 47.494825 \nL 198.874132 32.289231 \nL 199.178801 47.494825 \nL 199.788137 47.494825 \nL 200.092806 32.289231 \nL 200.397474 47.494825 \nL 200.702142 32.289231 \nL 201.311479 32.289231 \nL 201.616147 47.494825 \nL 202.225484 47.494825 \nL 202.530152 32.289231 \nL 202.83482 47.494825 \nL 203.139489 32.289231 \nL 203.748825 32.289231 \nL 204.053494 47.494825 \nL 204.358162 32.289231 \nL 205.576835 32.289231 \nL 205.881503 47.494825 \nL 206.186172 32.289231 \nL 207.100177 32.289231 \nL 207.404845 17.083636 \nL 207.709513 32.289231 \nL 208.014182 17.083636 \nL 208.31885 32.289231 \nL 208.928186 32.289231 \nL 209.232855 17.083636 \nL 209.537523 32.289231 \nL 209.842191 32.289231 \nL 210.14686 47.494825 \nL 210.451528 47.494825 \nL 210.756196 32.289231 \nL 211.974869 32.289231 \nL 212.279538 47.494825 \nL 212.584206 32.289231 \nL 213.498211 32.289231 \nL 213.802879 47.494825 \nL 214.107548 32.289231 \nL 214.412216 47.494825 \nL 214.716884 32.289231 \nL 215.326221 32.289231 \nL 215.630889 47.494825 \nL 215.935557 32.289231 \nL 216.240226 47.494825 \nL 216.544894 47.494825 \nL 216.849562 32.289231 \nL 217.154231 47.494825 \nL 217.458899 47.494825 \nL 217.763567 17.083636 \nL 218.068236 47.494825 \nL 218.372904 32.289231 \nL 218.677572 32.289231 \nL 218.98224 47.494825 \nL 219.591577 17.083636 \nL 219.896245 32.289231 \nL 220.505582 32.289231 \nL 220.81025 47.494825 \nL 221.114919 32.289231 \nL 221.419587 32.289231 \nL 221.724255 17.083636 \nL 222.028924 32.289231 \nL 222.63826 32.289231 \nL 222.942928 47.494825 \nL 223.247597 32.289231 \nL 223.856933 32.289231 \nL 224.161602 17.083636 \nL 224.46627 47.494825 \nL 224.770938 32.289231 \nL 225.684943 32.289231 \nL 225.989611 62.70042 \nL 226.29428 32.289231 \nL 226.598948 32.289231 \nL 226.903616 47.494825 \nL 227.208285 32.289231 \nL 227.512953 32.289231 \nL 227.817621 47.494825 \nL 228.12229 32.289231 \nL 229.036295 32.289231 \nL 229.340963 62.70042 \nL 229.950299 32.289231 \nL 230.254968 47.494825 \nL 230.559636 32.289231 \nL 231.473641 32.289231 \nL 231.778309 47.494825 \nL 232.387646 47.494825 \nL 232.692314 32.289231 \nL 233.301651 32.289231 \nL 233.606319 47.494825 \nL 233.910987 32.289231 \nL 234.520324 32.289231 \nL 234.824992 47.494825 \nL 235.129661 17.083636 \nL 235.434329 32.289231 \nL 235.738997 32.289231 \nL 236.043666 17.083636 \nL 236.348334 17.083636 \nL 236.653002 32.289231 \nL 237.567007 32.289231 \nL 237.871675 47.494825 \nL 238.481012 47.494825 \nL 238.78568 17.083636 \nL 239.090349 17.083636 \nL 239.395017 32.289231 \nL 239.699685 32.289231 \nL 240.004354 47.494825 \nL 240.309022 32.289231 \nL 240.61369 47.494825 \nL 240.918358 47.494825 \nL 241.223027 32.289231 \nL 241.527695 32.289231 \nL 241.832363 17.083636 \nL 242.137032 32.289231 \nL 243.660373 32.289231 \nL 243.965041 17.083636 \nL 244.574378 17.083636 \nL 244.879046 47.494825 \nL 245.183715 47.494825 \nL 245.488383 32.289231 \nL 245.793051 47.494825 \nL 246.09772 17.083636 \nL 246.402388 17.083636 \nL 246.707056 47.494825 \nL 247.011725 47.494825 \nL 247.316393 17.083636 \nL 247.621061 32.289231 \nL 248.230398 32.289231 \nL 248.535066 47.494825 \nL 248.839734 17.083636 \nL 249.144403 17.083636 \nL 249.449071 47.494825 \nL 250.058408 17.083636 \nL 250.363076 32.289231 \nL 251.886417 32.289231 \nL 252.191086 47.494825 \nL 252.495754 47.494825 \nL 252.800422 32.289231 \nL 253.105091 47.494825 \nL 253.409759 32.289231 \nL 253.714427 32.289231 \nL 254.019096 47.494825 \nL 254.628432 17.083636 \nL 254.9331 47.494825 \nL 255.237769 32.289231 \nL 255.847105 32.289231 \nL 256.151774 47.494825 \nL 256.456442 17.083636 \nL 256.76111 32.289231 \nL 257.065779 32.289231 \nL 257.370447 17.083636 \nL 257.675115 47.494825 \nL 258.284452 17.083636 \nL 258.58912 32.289231 \nL 258.893788 32.289231 \nL 259.198457 47.494825 \nL 259.503125 32.289231 \nL 260.112462 32.289231 \nL 260.41713 47.494825 \nL 260.721798 32.289231 \nL 261.026467 47.494825 \nL 261.331135 32.289231 \nL 262.549808 32.289231 \nL 262.854476 47.494825 \nL 263.159145 32.289231 \nL 263.463813 32.289231 \nL 263.768481 17.083636 \nL 264.07315 47.494825 \nL 264.377818 32.289231 \nL 266.205828 32.289231 \nL 266.510496 17.083636 \nL 267.119833 47.494825 \nL 267.424501 47.494825 \nL 267.729169 32.289231 \nL 268.033838 47.494825 \nL 268.643174 47.494825 \nL 268.947842 17.083636 \nL 269.252511 47.494825 \nL 269.557179 32.289231 \nL 270.166516 32.289231 \nL 270.471184 17.083636 \nL 270.775852 62.70042 \nL 271.080521 32.289231 \nL 271.689857 32.289231 \nL 271.994525 17.083636 \nL 272.299194 17.083636 \nL 272.603862 47.494825 \nL 272.90853 47.494825 \nL 273.213199 32.289231 \nL 273.517867 32.289231 \nL 273.822535 47.494825 \nL 274.127204 32.289231 \nL 274.431872 47.494825 \nL 274.73654 32.289231 \nL 275.041209 47.494825 \nL 275.345877 32.289231 \nL 276.259882 32.289231 \nL 276.56455 47.494825 \nL 276.869218 17.083636 \nL 277.173887 47.494825 \nL 277.478555 32.289231 \nL 277.783223 32.289231 \nL 278.087892 47.494825 \nL 278.39256 32.289231 \nL 279.001896 32.289231 \nL 279.306565 47.494825 \nL 279.611233 47.494825 \nL 279.915901 17.083636 \nL 280.22057 32.289231 \nL 280.525238 32.289231 \nL 280.829906 47.494825 \nL 281.134575 17.083636 \nL 281.439243 32.289231 \nL 281.743911 32.289231 \nL 282.04858 47.494825 \nL 282.353248 32.289231 \nL 283.571921 32.289231 \nL 283.876589 47.494825 \nL 284.181258 32.289231 \nL 287.227941 32.289231 \nL 287.532609 47.494825 \nL 287.837277 32.289231 \nL 288.446614 32.289231 \nL 288.751282 17.083636 \nL 289.055951 17.083636 \nL 289.360619 32.289231 \nL 289.665287 32.289231 \nL 289.969955 17.083636 \nL 290.274624 32.289231 \nL 290.579292 17.083636 \nL 291.188629 47.494825 \nL 291.493297 17.083636 \nL 292.102634 47.494825 \nL 292.407302 32.289231 \nL 293.016639 32.289231 \nL 293.321307 47.494825 \nL 293.625975 32.289231 \nL 294.235312 32.289231 \nL 294.53998 47.494825 \nL 294.844648 47.494825 \nL 295.149317 17.083636 \nL 295.453985 17.083636 \nL 295.758653 32.289231 \nL 296.063322 17.083636 \nL 296.36799 32.289231 \nL 297.281995 32.289231 \nL 297.586663 47.494825 \nL 297.891331 32.289231 \nL 298.196 47.494825 \nL 298.500668 32.289231 \nL 299.110005 32.289231 \nL 299.414673 17.083636 \nL 299.719341 17.083636 \nL 300.02401 47.494825 \nL 300.938014 47.494825 \nL 301.242683 32.289231 \nL 301.547351 32.289231 \nL 301.852019 47.494825 \nL 302.156688 32.289231 \nL 302.766024 32.289231 \nL 303.070693 47.494825 \nL 303.375361 32.289231 \nL 304.594034 32.289231 \nL 304.898702 47.494825 \nL 305.203371 32.289231 \nL 307.640717 32.289231 \nL 307.945385 47.494825 \nL 308.250054 32.289231 \nL 308.554722 47.494825 \nL 308.85939 47.494825 \nL 309.164059 32.289231 \nL 310.382732 32.289231 \nL 310.6874 17.083636 \nL 310.992068 32.289231 \nL 311.296737 32.289231 \nL 311.601405 47.494825 \nL 312.210742 47.494825 \nL 312.51541 32.289231 \nL 313.429415 32.289231 \nL 313.734083 17.083636 \nL 314.038752 17.083636 \nL 314.34342 47.494825 \nL 314.648088 32.289231 \nL 315.257425 32.289231 \nL 315.562093 47.494825 \nL 316.17143 47.494825 \nL 316.476098 32.289231 \nL 316.780766 47.494825 \nL 317.085435 47.494825 \nL 317.390103 32.289231 \nL 317.999439 32.289231 \nL 318.304108 47.494825 \nL 318.608776 32.289231 \nL 320.132118 32.289231 \nL 320.436786 47.494825 \nL 320.741454 32.289231 \nL 321.046123 32.289231 \nL 321.350791 17.083636 \nL 321.655459 32.289231 \nL 321.960127 17.083636 \nL 322.264796 32.289231 \nL 322.874132 32.289231 \nL 323.178801 47.494825 \nL 323.483469 32.289231 \nL 323.788137 47.494825 \nL 324.092806 47.494825 \nL 324.397474 32.289231 \nL 325.616147 32.289231 \nL 325.920815 17.083636 \nL 326.225484 47.494825 \nL 326.530152 32.289231 \nL 326.83482 32.289231 \nL 327.139489 47.494825 \nL 327.444157 47.494825 \nL 327.748825 17.083636 \nL 328.053494 32.289231 \nL 329.272167 32.289231 \nL 329.576835 17.083636 \nL 330.186172 47.494825 \nL 330.49084 47.494825 \nL 330.795508 32.289231 \nL 331.100177 32.289231 \nL 331.404845 17.083636 \nL 332.014182 47.494825 \nL 332.31885 32.289231 \nL 332.623518 32.289231 \nL 332.928186 47.494825 \nL 333.232855 32.289231 \nL 333.842191 32.289231 \nL 334.14686 47.494825 \nL 334.451528 32.289231 \nL 334.756196 47.494825 \nL 335.060865 17.083636 \nL 335.365533 32.289231 \nL 337.193543 32.289231 \nL 337.498211 47.494825 \nL 337.802879 32.289231 \nL 338.107548 47.494825 \nL 338.412216 47.494825 \nL 339.021553 17.083636 \nL 339.326221 32.289231 \nL 340.544894 32.289231 \nL 340.849562 47.494825 \nL 341.154231 47.494825 \nL 341.458899 32.289231 \nL 341.763567 32.289231 \nL 342.068236 47.494825 \nL 342.372904 32.289231 \nL 343.286909 32.289231 \nL 343.591577 47.494825 \nL 343.896245 32.289231 \nL 344.200914 47.494825 \nL 344.505582 32.289231 \nL 345.419587 32.289231 \nL 345.724255 17.083636 \nL 346.028924 47.494825 \nL 346.63826 17.083636 \nL 346.942928 17.083636 \nL 347.247597 47.494825 \nL 347.552265 32.289231 \nL 348.46627 32.289231 \nL 348.770938 47.494825 \nL 349.075607 32.289231 \nL 349.684943 32.289231 \nL 349.684943 32.289231 \n\" style=\"fill:none;stroke:#8dd3c7;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 30.103125 224.64 \nL 30.103125 7.2 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 364.903125 224.64 \nL 364.903125 7.2 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 30.103125 224.64 \nL 364.903125 224.64 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 30.103125 7.2 \nL 364.903125 7.2 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p851ac0055e\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"30.103125\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {}
    }
   ],
   "source": [
    "plt.plot(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}